{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comments Single LSTM Model 1(Complete).ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZCQZHI2fvGcm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://www.pyimagesearch.com/wp-content/uploads/2017/12/not_santa_detector_dl_logos.jpg)\n",
        "**This notebook attempts to tackle this classification problem by using Keras LSTM (Google Colab Version). After running the notebook, you can download both the trained model files and the result file **"
      ]
    },
    {
      "metadata": {
        "id": "RmkXeNiMZjGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "[Disclaimer]\n",
        "\n",
        "This notebook is originaled form Bongo's kernl on Kaggle\n",
        "\n",
        "https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras\n",
        "\n",
        "Based on Bongo's work, I have made the following enhancements:\n",
        "\n",
        "* add the prediction logic\n",
        "* add the code for viewing the result\n",
        "* add the code for exporting the model in files\n",
        "* add the code for downloading result data and model files\n",
        "* migrate the code to google's Colab environment\n",
        "\n",
        "\n",
        "**By Tony Yeung**\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ui4MHp4oxHUE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download the data from github into the workspace. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xt_Dm38xv6Pl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9715b7cf-3159-433d-d6b6-3a4326285115",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280328568,
          "user_tz": -480,
          "elapsed": 8420,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tonyyeung99/toxic_comments_data.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'toxic_comments_data'...\n",
            "remote: Counting objects: 7, done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "02hEi72bxv-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install the keras library"
      ]
    },
    {
      "metadata": {
        "id": "OcC2R04Ixo7T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AY5t0CrNx8VD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "metadata": {
        "id": "qrX88xW2x9Zr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cc2b7b7-7aaa-4b4d-9847-13a996368a9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280339277,
          "user_tz": -480,
          "elapsed": 7510,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_u9dJtdwyagj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Read the training data into pandas\n"
      ]
    },
    {
      "metadata": {
        "id": "ZQfbK-LOyNPr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " train = pd.read_csv('./toxic_comments_data/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3k75n9gyx8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read the testing data into pandas"
      ]
    },
    {
      "metadata": {
        "id": "DVAJW2-ryw0b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('./toxic_comments_data/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-T9fiMZcy6uS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5593a3cc-fa1b-412a-bdf1-8e391fb0996d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280342925,
          "user_tz": -480,
          "elapsed": 621,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "YAtGdoqozEO6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "21239b6e-def1-43e9-eaed-e88f68985986",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280343628,
          "user_tz": -480,
          "elapsed": 634,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train.isnull().any(),test.isnull().any()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(id               False\n",
              " comment_text     False\n",
              " toxic            False\n",
              " severe_toxic     False\n",
              " obscene          False\n",
              " threat           False\n",
              " insult           False\n",
              " identity_hate    False\n",
              " dtype: bool, id              False\n",
              " comment_text    False\n",
              " dtype: bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "4JuBtpKVzavi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see from the sneak peek, the dependent variables are in the training set itself so we need to split them up, into X and Y sets."
      ]
    },
    {
      "metadata": {
        "id": "amVwTz0rzLAq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values\n",
        "list_sentences_train = train[\"comment_text\"]\n",
        "list_sentences_test = test[\"comment_text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c0qixl5kziYh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The approach that we are taking is to feed the comments into the LSTM as part of the neural network but we can't just feed the words as it is. \n",
        "\n",
        "So this is what we are going to do:\n",
        "1. Tokenization - We need to break down the sentence into unique words. \n",
        "    For eg, \"I love cats and love dogs\" will become [\"I\",\"love\",\"cats\",\"and\",\"dogs\"]\n",
        "2. Indexing - We put the words in a dictionary-like structure and give them an index each\n",
        "    For eg, {1:\"I\",2:\"love\",3:\"cats\",4:\"and\",5:\"dogs\"}\n",
        "3. Index Representation- We could represent the sequence of words in the comments in the form of index, and feed this chain of index into our LSTM.\n",
        "    For eg, [1,2,3,4,2,5] "
      ]
    },
    {
      "metadata": {
        "id": "KvWOHoGYzsmh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fortunately, Keras has made our lives so much easier. If you are using the vanilla Tensorflow, you probably need to implement your own dictionary structure and handle the indexing yourself. In Keras, all the above steps can be done in 4 lines of code. Note that we have to define the number of unique words in our dictionary when tokenizing the sentences.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cm-cQpv4zhEK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IjnExXX0z2ID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, if you look at \"list_tokenized_train\", you will see that Keras has turned our words into index representation for us"
      ]
    },
    {
      "metadata": {
        "id": "MzmIiCtHzv06",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "dfc2decc-0733-4cd9-a7e7-1b37aac9996b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280371643,
          "user_tz": -480,
          "elapsed": 592,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "list_tokenized_train[:1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[688,\n",
              "  75,\n",
              "  1,\n",
              "  126,\n",
              "  130,\n",
              "  177,\n",
              "  29,\n",
              "  672,\n",
              "  4511,\n",
              "  12052,\n",
              "  1116,\n",
              "  86,\n",
              "  331,\n",
              "  51,\n",
              "  2278,\n",
              "  11448,\n",
              "  50,\n",
              "  6864,\n",
              "  15,\n",
              "  60,\n",
              "  2756,\n",
              "  148,\n",
              "  7,\n",
              "  2937,\n",
              "  34,\n",
              "  117,\n",
              "  1221,\n",
              "  15190,\n",
              "  2825,\n",
              "  4,\n",
              "  45,\n",
              "  59,\n",
              "  244,\n",
              "  1,\n",
              "  365,\n",
              "  31,\n",
              "  1,\n",
              "  38,\n",
              "  27,\n",
              "  143,\n",
              "  73,\n",
              "  3462,\n",
              "  89,\n",
              "  3085,\n",
              "  4583,\n",
              "  2273,\n",
              "  985]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "La_oswbv0Aox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But there's still 1 problem! What if some comments are terribly long, while some are just 1 word? Wouldn't our indexed-sentence look like this:\n",
        "   \n",
        "   Comment #1: [8,9,3,7,3,6,3,6,3,6,2,3,4,9]\n",
        "  \n",
        "  Comment #2: [1,2]\n",
        "\n",
        "And we have to feed a stream of data that has a consistent length(fixed number of features) isn't it?"
      ]
    },
    {
      "metadata": {
        "id": "Z-zsTSPj0E2w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And this is why we use \"padding\"! We could make the shorter sentences as long as the others by filling the shortfall by zeros.But on the other hand, we also have to trim the longer ones to the same length(maxlen) as the short ones. In this case, we have set the max length to be 200."
      ]
    },
    {
      "metadata": {
        "id": "IS4_tJCE0F15",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGKohY2e0KMw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How do you know what is the best \"maxlen\" to set? If you put it too short, you might lose some useful feature that could cost you some accuracy points down the path.If you put it too long, your LSTM cell will have to be larger to store the possible values or states.\n",
        "\n",
        "One of the ways to go about it is to see the distribution of the number of words in sentences."
      ]
    },
    {
      "metadata": {
        "id": "0_EWqe0Dz6di",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f8934106-8221-4563-8dc3-a3cf252581f6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280376069,
          "user_tz": -480,
          "elapsed": 675,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_t[:,195:200])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   89  3085  4583  2273   985]\n",
            " [ 2679   992   589  8377   182]\n",
            " [ 2394    93     1   737   468]\n",
            " ...\n",
            " [   12  8167  3509 13675  4528]\n",
            " [    9     7   151    34    11]\n",
            " [  363     3  1627  2056    88]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ScYagZ4K0QaY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mgir0fSf0UHB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "07952254-4377-4f71-8bc3-680398cfca78",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523280377773,
          "user_tz": -480,
          "elapsed": 938,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(totalNumWords,bins = np.arange(0,410,10))#[0,50,100,150,200,250,300,350,400])#,450,500,550,600,650,700,750,800,850,900])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQhkAklQoA0CSCmUASFKh/h+JLRNS1mEQ1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbe3f7c57f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OBNLbo2x0YIZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see, most of the sentence length is about 30+. We could set the \"maxlen\" to about 50, but I'm being paranoid so I have set to 200. Then again, it sounds like something you could experiment and see what is the magic number."
      ]
    },
    {
      "metadata": {
        "id": "k7fjLMoS0bdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the architecture of the model we are trying to build. It's always to good idea to list out the dimensions of each layer in the model to think visually and help you to debug later on.\n",
        "![](https://i.imgur.com/txJomEa.png)"
      ]
    },
    {
      "metadata": {
        "id": "rrD5LWbq0fjp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As mentioned earlier, the inputs into our networks are our list of encoded sentences. We begin our defining an Input layer that accepts a list of sentences that has a dimension of 200.\n",
        "![](https://i.imgur.com/uSjU4J7.png)\n",
        "By indicating an empty space after comma, we are telling Keras to infer the number automatically."
      ]
    },
    {
      "metadata": {
        "id": "UZCmbOeh0WD6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xuk4QYm0nZR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we pass it to our Embedding layer, where we project the words to a defined vector space depending on the distance of the surrounding words in a sentence. Embedding allows us to reduce model size and most importantly the huge dimensions we have to deal with, in the case of using one-hot encoding to represent the words in our sentence.\n",
        "![](https://www.tensorflow.org/versions/r0.12/images/embedding-custom-projection.png)\n",
        "The output of the Embedding layer is just a list of the coordinates of the words in this vector space. For eg. (-81.012) for \"cat\" and  (-80.012) for \"dog\". We could also use the distance of these coordinates to detect relevance and context. Embedding is a pretty deep topic, and if you are interested, this is a comprehensive guide: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/"
      ]
    },
    {
      "metadata": {
        "id": "qUZD4VZO0rtR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to define the size of the \"vector space\" we have mentioned above, and the number of unique words(max_features) we are using. Again, the embedding size is a parameter that you can tune and experiment."
      ]
    },
    {
      "metadata": {
        "id": "0k_r8T3y0l15",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "x = Embedding(max_features, embed_size)(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKKPBBQS02Ao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The embedding layer outputs a 3-D tensor of (None, 200, 128). Which is an array of sentence(None means that it's size is inferred), and for each words(200), there is an array of 128 coordinates in the vector space of embedding. "
      ]
    },
    {
      "metadata": {
        "id": "2pEqjfm507Mw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we feed this Tensor into the LSTM layer. We set the LSTM to produce an output that has a dimension of 60 and want it to return the whole unrolled sequence of results. As you probably know, LSTM or RNN works by recursively feeding the output of a previous network into the input of the current network, and you would take the final output after X number of recursion. But depending on use cases, you might want to take the unrolled, or the outputs of each recursion as the result to pass to the next layer. And this is the case."
      ]
    },
    {
      "metadata": {
        "id": "__3l3gmf0-ts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)"
      ]
    },
    {
      "metadata": {
        "id": "cU1C1azs1B9i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the short line of code that defines the LSTM layer, it's easy to miss the required input dimensions. LSTM takes in a tensor of [Batch Size, Time Steps, Number of Inputs]. Batch size is the number of samples in a batch, time steps is the number of recursion it runs for each input, or it could be pictured as the number of \"A\"s in the above picture. Lastly, number of inputs is the number of variables(number of words in each sentence in our case) you pass into LSTM as pictured in \"x\" above."
      ]
    },
    {
      "metadata": {
        "id": "KiUXw1v_1Gvy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can make use of the output from the previous embedding layer which outputs a 3-D tensor of (None, 200, 128) into the LSTM layer. What it does is going through the samples, recursively run the LSTM model for 200 times, passing in the coordinates of the words each time. And because we want the unrolled version, we will receive a Tensor shape of (None, 200, 60), where 60 is the output dimension we have defined."
      ]
    },
    {
      "metadata": {
        "id": "bsb4obQf1Iry",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtKrM_-N1Nik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before we could pass the output to a normal layer, we need to reshape the 3D tensor into a 2D one. We reshape carefully to avoid throwing away data that is important to us, and ideally we want the resulting data to be a good representative of the original data.\n",
        "\n",
        "Therefore, we use a Global Max Pooling layer which is traditionally used in CNN problems to reduce the dimensionality of image data. In simple terms, we go through each patch of data, and we take the maximum values of each patch. These collection of maximum values will be a new set of down-sized data we can use.\n",
        "\n",
        "As you can see from other Kaggle kernels, different variants (Average,Max,etc) of pooling layers are used for dimensionality reduction and they could yield different results so do try them out.\n",
        "\n",
        "If you are interested in finding out the technical details of pooling, read up here: https://wiseodd.github.io/techblog/2016/07/18/convnet-maxpool-layer/"
      ]
    },
    {
      "metadata": {
        "id": "y2iIZc_R01Ox",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = GlobalMaxPool1D()(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EULKP4HC1RNx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With a 2D Tensor in our hands, we pass it to a Dropout layer which indiscriminately \"disable\" some nodes so that the nodes in the next layer is forced to handle the representation of the missing data and the whole network could result in better generalization.\n",
        "![](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/dropout.jpeg)\n",
        "\n",
        "We set the dropout layer to drop out 10%(0.1) of the nodes."
      ]
    },
    {
      "metadata": {
        "id": "KxLoVemj1WJh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIzwV08R1ZsB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After a drop out layer, we connect the output of drop out layer to a densely connected layer and the output passes through a RELU function. In short, this is what it does:\n",
        "\n",
        "**Activation( (Input X Weights) + Bias)**\n",
        "\n",
        "all in 1 line, with the weights, bias and activation layer all set up for you! \n",
        "We have defined the Dense layer to produce a output dimension of 50."
      ]
    },
    {
      "metadata": {
        "id": "zP6cg13r1aN5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = Dense(50, activation=\"relu\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ocRdtN2P1cwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We feed the output into a Dropout layer again."
      ]
    },
    {
      "metadata": {
        "id": "PTdGNQN01ekK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYKq-so-1gkJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we feed the output into a Sigmoid layer. The reason why sigmoid is used is because we are trying to achieve a binary classification(1,0) for each of the 6 labels, and the sigmoid function will squash the output between the bounds of 0 and 1."
      ]
    },
    {
      "metadata": {
        "id": "X6yOSs4D1iwy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = Dense(6, activation=\"sigmoid\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zg7JDsH21lJ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are almost done! All is left is to define the inputs, outputs and configure the learning process. We have set our model to optimize our loss function using Adam optimizer, define the loss function to be \"binary_crossentropy\" since we are tackling a binary classification. In case you are looking for the learning rate, the default is set at 0.001."
      ]
    },
    {
      "metadata": {
        "id": "pEc9eD6h1nDZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sH9IpcuB1o1y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The moment that we have been waiting for as arrived! It's finally time to put our model to the test. We'll feed in a list of 32 padded, indexed sentence for each batch and split 10% of the data as a validation set. This validation set will be used to assess whether the model has overfitted, for each batch. The model will also run for 2 epochs. These are some of the tunable parameters that you can experiment with, to see if you can push the accurate to the next level without crashing your machine(hence the batch size)."
      ]
    },
    {
      "metadata": {
        "id": "FdlKKCoa1rdy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8c756fd7-4ef5-4b20-9b53-576726ceccef",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523284885042,
          "user_tz": -480,
          "elapsed": 4500336,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/2\n",
            " 21440/143613 [===>..........................] - ETA: 31:06 - loss: 0.1582 - acc: 0.9596"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "143584/143613 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9773"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r143613/143613 [==============================] - 2247s 16ms/step - loss: 0.0707 - acc: 0.9773 - val_loss: 0.0508 - val_acc: 0.9817\n",
            "Epoch 2/2\n",
            " 10112/143613 [=>............................] - ETA: 34:00 - loss: 0.0437 - acc: 0.9834"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "143584/143613 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r143613/143613 [==============================] - 2252s 16ms/step - loss: 0.0446 - acc: 0.9835 - val_loss: 0.0472 - val_acc: 0.9827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbe3895b588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "ssFnlDUg1z6x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Seems that the accuracy is pretty decent for a basic attempt! There's a lot that you could do (see TODO below) to further improve the accuracy so feel free to fork the kernel and experiment for yourself!\n",
        "\n",
        "Tony Yeung\n",
        "Additional tips and tricks\n",
        "\n",
        "1) If you have hit some roadblocks, especially when it starts returning dimension related errors, a good idea is to run \"model.summary()\" because it lists out all your layer outputs, which is pretty useful for diagnosis.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ULD67fuJ11oC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ac1381d4-34b0-4f6c-9b1e-3adfed90b0fd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523284885675,
          "user_tz": -480,
          "elapsed": 563,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 200, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 200, 60)           45360     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                3050      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 2,608,716\n",
            "Trainable params: 2,608,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xgBVwHoT13Gh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Saving Model"
      ]
    },
    {
      "metadata": {
        "id": "h69hAh0t15Hp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5xG-3WI71-yl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"model_toxic_comment1.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaDbSW4E2AoB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ae4be8-c953-45a0-8439-9538a2176d09",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523284887756,
          "user_tz": -480,
          "elapsed": 600,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model_toxic_com.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9d6Q5naD1_Vi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2540005-1f01-4733-8f21-25ef39e00a48",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523284889583,
          "user_tz": -480,
          "elapsed": 1734,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  model_toxic_com.h5  model_toxic_comment1.json\ttoxic_comments_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P1SvmCLL2EER",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('model_toxic_comment1.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkQ_EI-42FsB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('model_toxic_com.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpuM-Cek2G-1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Prediction on test data set **"
      ]
    },
    {
      "metadata": {
        "id": "AxGgybqW2dWU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8c551006-31b6-43a9-da34-31be15cad0f7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523285487089,
          "user_tz": -480,
          "elapsed": 580839,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(X_te, verbose=1)\n",
        "print(result)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 580s 4ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[[9.97153997e-01 3.54507387e-01 9.63909328e-01 7.05523118e-02\n",
            "  8.99317026e-01 2.77550042e-01]\n",
            " [7.89373124e-04 2.48586247e-07 7.86491801e-05 2.94651568e-06\n",
            "  1.73644185e-05 1.10216515e-05]\n",
            " [1.78701337e-03 5.62350078e-06 3.14650883e-04 2.43296199e-05\n",
            "  9.64407081e-05 5.36826046e-05]\n",
            " ...\n",
            " [3.90446221e-04 6.34174739e-08 5.00906717e-05 6.52309268e-07\n",
            "  8.28824159e-06 4.76135529e-06]\n",
            " [9.69497487e-03 3.10709288e-06 8.84907262e-04 3.09942006e-05\n",
            "  3.13416502e-04 2.11338978e-04]\n",
            " [9.62549448e-01 9.11382306e-03 7.51952112e-01 2.24721944e-03\n",
            "  3.62438977e-01 2.39719469e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HloFmu1J2mOP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#class_col = pd.DataFrame({'toxic':result[:,0].tolist(), 'threat':result[:,3].tolist(), 'insult':result[:,4].tolist(), 'identity_hate':result[:,5].tolist()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DBbW0TySUnWf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_col = pd.DataFrame({'toxic':result[:,0].tolist(), 'severe_toxic':result[:,1].tolist(), 'obscene':result[:,2].tolist(), 'threat':result[:,3].tolist(), 'insult':result[:,4].tolist(), 'identity_hate':result[:,5].tolist()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nfn6BULE204Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding back the id to the prediction result "
      ]
    },
    {
      "metadata": {
        "id": "1kg87zYt2vBP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "id_col = test[\"id\"]\n",
        "frames = [id_col, class_col]\n",
        "#frames = [test, class_col]\n",
        "merged = pd.concat(frames, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4j5C0pEW3Drw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show the prediction result"
      ]
    },
    {
      "metadata": {
        "id": "gkCRsGO93H5Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2274
        },
        "outputId": "5d7486f8-5a19-42b2-87b4-4575c290d76b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523285670705,
          "user_tz": -480,
          "elapsed": 997,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(merged)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      id  identity_hate    insult   obscene  severe_toxic  \\\n",
            "0       00001cee341fdb12       0.277550  0.899317  0.963909  3.545074e-01   \n",
            "1       0000247867823ef7       0.000011  0.000017  0.000079  2.485862e-07   \n",
            "2       00013b17ad220c46       0.000054  0.000096  0.000315  5.623501e-06   \n",
            "3       00017563c3f7919a       0.000014  0.000027  0.000121  3.621091e-07   \n",
            "4       00017695ad8997eb       0.000126  0.000191  0.000625  1.630925e-05   \n",
            "5       0001ea8717f6de06       0.000021  0.000041  0.000131  8.187254e-07   \n",
            "6       00024115d4cbde0f       0.000009  0.000019  0.000089  1.416676e-07   \n",
            "7       000247e83dcc1211       0.024488  0.084513  0.098473  5.300542e-03   \n",
            "8       00025358d4737918       0.000491  0.001517  0.002944  3.967977e-06   \n",
            "9       00026d1092fe71cc       0.000001  0.000002  0.000017  1.172126e-08   \n",
            "10      0002eadc3b301559       0.008147  0.018872  0.073510  3.101327e-04   \n",
            "11      0002f87b16116a7f       0.002067  0.005639  0.016614  2.286456e-05   \n",
            "12      0003806b11932181       0.000011  0.000022  0.000103  1.996489e-07   \n",
            "13      0003e1cccfd5a40a       0.000004  0.000006  0.000043  6.505649e-08   \n",
            "14      00059ace3e3e9a53       0.000004  0.000005  0.000041  6.741837e-08   \n",
            "15      000634272d0d44eb       0.000011  0.000021  0.000112  3.858858e-07   \n",
            "16      000663aff0fffc80       0.000682  0.001718  0.006051  1.901762e-04   \n",
            "17      000689dd34e20979       0.000009  0.000016  0.000084  1.928137e-07   \n",
            "18      000834769115370c       0.000026  0.000042  0.000228  2.880611e-07   \n",
            "19      000844b52dee5f3f       0.000667  0.001742  0.005699  1.576434e-04   \n",
            "20      00084da5d4ead7aa       0.000199  0.000304  0.000874  2.398901e-05   \n",
            "21      00091c35fa9d0465       0.023241  0.080578  0.092166  1.582960e-03   \n",
            "22      000968ce11f5ee34       0.003417  0.008779  0.006598  1.105218e-04   \n",
            "23      0009734200a85047       0.000003  0.000005  0.000039  4.768648e-08   \n",
            "24      00097b6214686db5       0.001793  0.004986  0.006214  4.106967e-05   \n",
            "25      0009aef4bd9e1697       0.000007  0.000010  0.000063  7.367832e-08   \n",
            "26      000a02d807ae0254       0.000063  0.000128  0.000404  2.408848e-06   \n",
            "27      000a6c6d4e89b9bc       0.000175  0.000415  0.000934  9.653295e-06   \n",
            "28      000bafe2080bba82       0.036070  0.114080  0.045739  2.262625e-03   \n",
            "29      000bf0a9894b2807       0.000014  0.000024  0.000122  2.784135e-07   \n",
            "...                  ...            ...       ...       ...           ...   \n",
            "153134  fff3ae2e177b6bb3       0.000041  0.000064  0.000307  7.789924e-07   \n",
            "153135  fff4109e837f7acc       0.000007  0.000013  0.000073  1.665705e-07   \n",
            "153136  fff4373a81ef9f2a       0.000005  0.000007  0.000049  6.454037e-08   \n",
            "153137  fff460574ddbcd80       0.000764  0.001148  0.001967  2.561452e-05   \n",
            "153138  fff4fc0a1555be5c       0.000116  0.000169  0.000595  6.333905e-06   \n",
            "153139  fff5b9bb944d634c       0.000009  0.000017  0.000085  2.464068e-07   \n",
            "153140  fff5c4a77fe0c05f       0.000153  0.000335  0.000738  1.192510e-05   \n",
            "153141  fff5fb61bd637c82       0.000005  0.000008  0.000049  8.568330e-08   \n",
            "153142  fff69311f306df44       0.000203  0.000315  0.001004  1.571060e-05   \n",
            "153143  fff6ad63666fb304       0.059827  0.441480  0.872067  5.244990e-02   \n",
            "153144  fff7159b3ee95618       0.000269  0.000674  0.000977  1.775192e-05   \n",
            "153145  fff718ffe5f05559       0.000012  0.000018  0.000105  2.049065e-07   \n",
            "153146  fff7fc22a0cdccd3       0.000011  0.000013  0.000080  2.225302e-07   \n",
            "153147  fff83b80284d8440       0.000035  0.000056  0.000221  1.622088e-06   \n",
            "153148  fff8ef316d0c6990       0.000010  0.000015  0.000082  3.501331e-07   \n",
            "153149  fff8f521a7dbcd47       0.043001  0.172576  0.201853  8.263970e-03   \n",
            "153150  fff8f64043129fa2       0.000015  0.000025  0.000119  2.149864e-07   \n",
            "153151  fff9d70fe0722906       0.016764  0.215689  0.426588  2.855457e-03   \n",
            "153152  fff9fa508f400ee6       0.019034  0.069178  0.198537  1.817832e-03   \n",
            "153153  fffa3fae1890b40a       0.065859  0.241264  0.470846  1.372929e-02   \n",
            "153154  fffa8a11c4378854       0.027028  0.251842  0.108211  3.397134e-03   \n",
            "153155  fffac2a094c8e0e2       0.114992  0.741164  0.900923  9.302887e-02   \n",
            "153156  fffb5451268fb5ba       0.000089  0.000148  0.000476  3.415745e-06   \n",
            "153157  fffc2b34bbe61c8d       0.000006  0.000009  0.000062  1.136895e-07   \n",
            "153158  fffc489742ffe69b       0.019953  0.411771  0.293807  4.636427e-03   \n",
            "153159  fffcd0960ee309b5       0.015298  0.062322  0.149178  1.378749e-03   \n",
            "153160  fffd7a9a6eb32c16       0.000445  0.000712  0.001769  1.530026e-05   \n",
            "153161  fffda9e8d6fafa9e       0.000005  0.000008  0.000050  6.341747e-08   \n",
            "153162  fffe8f1340a79fc2       0.000211  0.000313  0.000885  3.107093e-06   \n",
            "153163  ffffce3fb183ee80       0.023972  0.362439  0.751952  9.113823e-03   \n",
            "\n",
            "              threat     toxic  \n",
            "0       7.055231e-02  0.997154  \n",
            "1       2.946516e-06  0.000789  \n",
            "2       2.432962e-05  0.001787  \n",
            "3       2.563450e-06  0.000879  \n",
            "4       6.607974e-05  0.002947  \n",
            "5       8.588399e-06  0.001240  \n",
            "6       1.220759e-06  0.000897  \n",
            "7       7.348313e-03  0.510142  \n",
            "8       2.886422e-05  0.035740  \n",
            "9       1.570596e-07  0.000145  \n",
            "10      8.582380e-04  0.303879  \n",
            "11      1.300627e-04  0.105835  \n",
            "12      1.628870e-06  0.000899  \n",
            "13      5.231969e-07  0.000299  \n",
            "14      6.304781e-07  0.000231  \n",
            "15      2.216094e-06  0.000706  \n",
            "16      2.808135e-04  0.021219  \n",
            "17      1.443116e-06  0.000644  \n",
            "18      2.850425e-06  0.001898  \n",
            "19      2.495792e-04  0.021843  \n",
            "20      1.001918e-04  0.004326  \n",
            "21      4.090946e-03  0.458938  \n",
            "22      1.051382e-03  0.121972  \n",
            "23      4.417747e-07  0.000255  \n",
            "24      3.149141e-04  0.102905  \n",
            "25      8.937113e-07  0.000492  \n",
            "26      1.402732e-05  0.003345  \n",
            "27      5.499448e-05  0.008724  \n",
            "28      1.596455e-02  0.517450  \n",
            "29      2.094459e-06  0.000918  \n",
            "...              ...       ...  \n",
            "153134  6.375667e-06  0.001916  \n",
            "153135  1.309752e-06  0.000503  \n",
            "153136  6.296783e-07  0.000337  \n",
            "153137  2.633726e-04  0.025513  \n",
            "153138  4.138490e-05  0.003707  \n",
            "153139  1.840099e-06  0.000683  \n",
            "153140  6.363885e-05  0.007051  \n",
            "153141  8.296309e-07  0.000409  \n",
            "153142  8.206467e-05  0.005307  \n",
            "153143  8.482572e-03  0.975669  \n",
            "153144  1.162846e-04  0.012859  \n",
            "153145  2.040739e-06  0.000712  \n",
            "153146  2.646714e-06  0.000544  \n",
            "153147  1.129753e-05  0.001485  \n",
            "153148  2.517205e-06  0.000496  \n",
            "153149  1.009783e-02  0.725382  \n",
            "153150  2.451187e-06  0.001175  \n",
            "153151  2.274755e-03  0.875752  \n",
            "153152  2.774143e-03  0.584808  \n",
            "153153  1.479252e-02  0.683879  \n",
            "153154  6.399448e-03  0.804405  \n",
            "153155  2.415707e-02  0.985674  \n",
            "153156  2.743449e-05  0.003743  \n",
            "153157  1.045174e-06  0.000395  \n",
            "153158  2.407025e-03  0.947915  \n",
            "153159  2.184075e-03  0.587440  \n",
            "153160  1.051104e-04  0.014043  \n",
            "153161  6.523093e-07  0.000390  \n",
            "153162  3.099420e-05  0.009695  \n",
            "153163  2.247219e-03  0.962549  \n",
            "\n",
            "[153164 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "42fEISJ_3MYX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "View result page\n",
        "(You can view different result page by changing the variable batch_line)"
      ]
    },
    {
      "metadata": {
        "id": "Z_MGix5U3ZDy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "f2132045-5dcb-4829-87fa-15de2d0af48e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523285677323,
          "user_tz": -480,
          "elapsed": 715,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', 400)\n",
        "batch_line = 18\n",
        "merged[(batch_line-1) * 10: 10*batch_line]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>insult</th>\n",
              "      <th>obscene</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>threat</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>00441d96a027ea2d</td>\n",
              "      <td>0.150128</td>\n",
              "      <td>0.367722</td>\n",
              "      <td>0.213246</td>\n",
              "      <td>4.487314e-02</td>\n",
              "      <td>0.082848</td>\n",
              "      <td>0.785949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>004515df90b06ef9</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>1.570575e-05</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.004698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>004540f1a3bba137</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>1.546400e-06</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.001594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>00463993d4325375</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>1.503070e-06</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.001312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>004651d6884295bf</td>\n",
              "      <td>0.055014</td>\n",
              "      <td>0.630271</td>\n",
              "      <td>0.529611</td>\n",
              "      <td>2.169803e-02</td>\n",
              "      <td>0.010043</td>\n",
              "      <td>0.967748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>0046db897eaa12e7</td>\n",
              "      <td>0.139210</td>\n",
              "      <td>0.830962</td>\n",
              "      <td>0.910333</td>\n",
              "      <td>1.926203e-01</td>\n",
              "      <td>0.023680</td>\n",
              "      <td>0.995804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>0046f41333aebfe7</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>7.979305e-07</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.002174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>0047582c40509d2d</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>8.984935e-07</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.010374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>004793abaf67dd8e</td>\n",
              "      <td>0.069577</td>\n",
              "      <td>0.372942</td>\n",
              "      <td>0.260844</td>\n",
              "      <td>2.106522e-02</td>\n",
              "      <td>0.019515</td>\n",
              "      <td>0.859263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>004902b29a55acae</td>\n",
              "      <td>0.011597</td>\n",
              "      <td>0.054395</td>\n",
              "      <td>0.170699</td>\n",
              "      <td>9.227132e-04</td>\n",
              "      <td>0.001464</td>\n",
              "      <td>0.614936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  identity_hate    insult   obscene  severe_toxic  \\\n",
              "170  00441d96a027ea2d       0.150128  0.367722  0.213246  4.487314e-02   \n",
              "171  004515df90b06ef9       0.000159  0.000268  0.000819  1.570575e-05   \n",
              "172  004540f1a3bba137       0.000036  0.000063  0.000233  1.546400e-06   \n",
              "173  00463993d4325375       0.000029  0.000051  0.000198  1.503070e-06   \n",
              "174  004651d6884295bf       0.055014  0.630271  0.529611  2.169803e-02   \n",
              "175  0046db897eaa12e7       0.139210  0.830962  0.910333  1.926203e-01   \n",
              "176  0046f41333aebfe7       0.000038  0.000060  0.000193  7.979305e-07   \n",
              "177  0047582c40509d2d       0.000085  0.000247  0.000468  8.984935e-07   \n",
              "178  004793abaf67dd8e       0.069577  0.372942  0.260844  2.106522e-02   \n",
              "179  004902b29a55acae       0.011597  0.054395  0.170699  9.227132e-04   \n",
              "\n",
              "       threat     toxic  \n",
              "170  0.082848  0.785949  \n",
              "171  0.000067  0.004698  \n",
              "172  0.000011  0.001594  \n",
              "173  0.000010  0.001312  \n",
              "174  0.010043  0.967748  \n",
              "175  0.023680  0.995804  \n",
              "176  0.000010  0.002174  \n",
              "177  0.000015  0.010374  \n",
              "178  0.019515  0.859263  \n",
              "179  0.001464  0.614936  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "UW0ApGAr3eEp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Last but not least : Save the result to the workspace "
      ]
    },
    {
      "metadata": {
        "id": "pMmUvTgtUxri",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "merged.to_csv('toxic_comment_submit.csv', sep=',', index = False, float_format='%.1f', columns=[\"id\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\", \"identity_hate\" ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7MEdnckUyJd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "225a91f2-925e-41dd-f526-31d77c8325ea",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523285702149,
          "user_tz": -480,
          "elapsed": 3975,
          "user": {
            "displayName": "Tony Yeung",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102507755674271928464"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\t\t    model_toxic_comment1.json  toxic_comment_submit.csv\r\n",
            "model_toxic_com.h5  toxic_comments_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qcQ6m5SmVCwg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That is! Now you can download all the model files and result files"
      ]
    },
    {
      "metadata": {
        "id": "4T2A0sZpU17-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('model_toxic_comment1.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eu3IEAKCVKe3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('model_toxic_com.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NACmQhl7VPdc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('toxic_comment_submit.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-9cRMAc55Td",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}